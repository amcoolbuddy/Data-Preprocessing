{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27d3276e-d665-403e-87f1-58de7e364146",
   "metadata": {},
   "source": [
    "# Here we starting all the process of data preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519dfe73-1025-4d81-a3e8-b1bdeb21e193",
   "metadata": {},
   "source": [
    "### IMPORTING THE LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a96134b1-36f4-4d81-905b-d80cc1f259b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a860c0f-aa84-402b-9462-0cf3e662962d",
   "metadata": {},
   "source": [
    "### IMPORTING THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "859d45fa-9109-46ad-b109-51d1d53105b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>France</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>France</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Germany</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>France</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes\n",
       "5   France  35.0  58000.0       Yes\n",
       "6    Spain   NaN  52000.0        No\n",
       "7   France  48.0  79000.0       Yes\n",
       "8  Germany  50.0  83000.0        No\n",
       "9   France  37.0  67000.0       Yes"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt=pd.read_csv('data.csv')\n",
    "dt"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c7640bea-937a-49b3-b47e-42fc22f1ecf7",
   "metadata": {},
   "source": [
    "Now we gaing to create two new entities--\n",
    "First one is metrics of features.\n",
    "Second one is dependent variable vectors.\n",
    "We are creating these two entities because we are going to build our future machine learning models that expect these two entities in their inputs separately, that's the only reason why we have two create these two separate entities.In any dataset with which you are going to train a machine learning model you have the same entities which are features and the dependent variable vectors. The features are the columns with which you are gonna predict the dependent variable.Here the features are also called as independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ddfc8805-65a6-497b-9691-83ade31d6e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Syntax= df.iloc[row_position, column_position]\n",
    "x=dt.iloc[ :,:-1].values\n",
    "y=dt.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "726fe140-e779-4464-b3cf-5ee6f3baa62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 nan]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' nan 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9d82fc9-d3a4-48f5-889e-7ae5e4944a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725ba364-eb6f-4b70-9c1d-cc3cb6167362",
   "metadata": {},
   "source": [
    "### HANDLING MISSING DATA\n",
    "\n",
    "- Here we are going to use scikit learn to handle missing data.\n",
    "- The calss we are going to use from scikit learn is simple imputer. First we are going to import the simple imputer than going to create the instance of that class, this object will allow us to exactly replace this missing salary here by average of the salaries and then we will have an updated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b51f5378-dd14-4c8f-a71a-96bf68620f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy='mean') # this is just an object \n",
    "# Now applying this to our matrix of features.\n",
    "imputer.fit(x[:,1:3])\n",
    "x[:,1:3] = imputer.transform(x[:,1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8946be75-f7dd-487b-80a2-cec3b1851429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 63777.77777777778]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' 38.77777777777778 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba38df9c-d23b-4b18-a8b6-f2797396e311",
   "metadata": {},
   "source": [
    "### ENCODING CATEGORICAL DATA \n",
    "\n",
    "- It will be difficult for machine learning model to compute some correlation between these columns, the features and the outcomes(dependent variable) and therefore we will have to turn these strings, these categories into numbers.\n",
    "- Here we are going to perform one hot encoding. To do this we are going to use two classes first one is the column transformer class from the composed module of scikit learn library and the second class is one hot encoder class from the preprocessing modules of the same scikit learn library.\n",
    "- CT use below is basically column transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1e3154e-17f5-4a23-a304-0bf334fd88a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct= ColumnTransformer(transformers = [('encoder',OneHotEncoder(), [0])], remainder='passthrough') ## Not yet connected to our matrix of features.\n",
    "x = np.array(ct.fit_transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca24531b-452c-46da-9e98-aac9ed9442e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 1.0 0.0 0.0 44.0 72000.0]\n",
      " [1.0 0.0 0.0 1.0 27.0 48000.0]\n",
      " [1.0 0.0 1.0 0.0 30.0 54000.0]\n",
      " [1.0 0.0 0.0 1.0 38.0 61000.0]\n",
      " [1.0 0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [0.0 1.0 0.0 0.0 35.0 58000.0]\n",
      " [1.0 0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [0.0 1.0 0.0 0.0 48.0 79000.0]\n",
      " [1.0 0.0 1.0 0.0 50.0 83000.0]\n",
      " [0.0 1.0 0.0 0.0 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f206f809-a678-41c6-8147-536576b63dc8",
   "metadata": {},
   "source": [
    "Now we are going to convert the categorical value of dependent variable(i.e. Yes and No) into 1 and 0. For this we are going to use the label encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c114e3cd-fe17-4288-8174-e32761d38d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y= le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce2eae4d-91ae-4076-bad5-e87a02bbc0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f332966d-2f4e-4440-9b84-39b3e380f918",
   "metadata": {},
   "source": [
    "## SPLITTING DATASET INTO TRAINING AND TESTING DATA  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9c50238-ac0e-4e1f-a2b5-3acfe7a112fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ce93b9d-453a-40f7-93b8-96211764ec26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [1.0 0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [0.0 1.0 0.0 0.0 44.0 72000.0]\n",
      " [1.0 0.0 0.0 1.0 38.0 61000.0]\n",
      " [1.0 0.0 0.0 1.0 27.0 48000.0]\n",
      " [0.0 1.0 0.0 0.0 48.0 79000.0]\n",
      " [1.0 0.0 1.0 0.0 50.0 83000.0]\n",
      " [0.0 1.0 0.0 0.0 35.0 58000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "74093061-e85d-4624-8c11-437a021fb904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 1.0 0.0 30.0 54000.0]\n",
      " [0.0 1.0 0.0 0.0 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8df40c18-fcb7-4866-9109-2bd2658e11f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5204b1bd-5190-441f-9f72-6a538c2a414e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575bf3f5-2772-40d0-aa85-4d65486bd1e0",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "- Feature scaling helps us to put all the features on the same scale\n",
    "- For some of the machine learning model inorder to avoid some features to be dominated by other features we need feature scaling.It is not required to apply feature scaling in every machine learning model , it is required in some of them only where the value of variables vary a lot.\n",
    "- There are two main feature scaling techniques:-\n",
    "- Standardization-> Consist of subtracting each value of your feature by mean of all the values of the feature and then deviding by standard deviation which is square root of the variance. And this will put all the values of the feature between aroung -3 and +3. When you apply this transformation on all the features of your dataset then all the features will take value between around -3 and +3.\n",
    "- Normalization -> Consist of subtracting each value of your feature by minimum value of the feature and then deviding by the difference between maximum value of feature and minimum value of feature, All the values of our feature will become between 0 and 1.\n",
    "- Normalization is recommended when you have a normal distribution in most of your features.\n",
    "- Standardization actually works well all the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bdf42848-4ece-42f3-8467-77c61d1f6d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train[:,3:] =sc.fit_transform(x_train[:,3:])\n",
    "x_test[:,3:]=sc.transform(x_test[:,3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "60eb8b13-40df-480f-809f-446c4749b069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 0.0 1.2909944487358056 -0.19159184384578545 -1.0781259408412425]\n",
      " [1.0 0.0 1.0 -0.7745966692414834 -0.014117293757057777\n",
      "  -0.07013167641635372]\n",
      " [0.0 1.0 0.0 -0.7745966692414834 0.566708506533324 0.633562432710455]\n",
      " [1.0 0.0 0.0 1.2909944487358056 -0.30453019390224867\n",
      "  -0.30786617274297867]\n",
      " [1.0 0.0 0.0 1.2909944487358056 -1.9018011447007988 -1.420463615551582]\n",
      " [0.0 1.0 0.0 -0.7745966692414834 1.1475343068237058 1.232653363453549]\n",
      " [1.0 0.0 1.0 -0.7745966692414834 1.4379472069688968 1.5749910381638885]\n",
      " [0.0 1.0 0.0 -0.7745966692414834 -0.7401495441200351 -0.5646194287757332]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0000c301-17b5-4a37-9f1f-1363312dfed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 1.0 -0.7745966692414834 -1.4661817944830124 -0.9069571034860727]\n",
      " [0.0 1.0 0.0 -0.7745966692414834 -0.44973664397484414 0.2056403393225306]]\n"
     ]
    }
   ],
   "source": [
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4f131e-fcc1-4ab6-a4fd-cf0e044bc4eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
